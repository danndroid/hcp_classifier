{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c80315-d33d-479c-8a59-1ddeef0a98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GATv2Conv, GCNConv, GlobalAttention\n",
    "from torch_geometric.utils import dropout_edge\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510b3a05-0118-4adb-a04d-24fd3f7d4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../../code/'))\n",
    "from utils.graph_features import create_graph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea488eeb-8703-44a8-b465-064473ebf34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARRIOR\n",
      "   brain initialized\n",
      "   network initialized\n"
     ]
    }
   ],
   "source": [
    "import warrior as war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bdccdc-de4f-4dc7-a30c-a8d958999628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 100, 100)\n",
      "(10, 100, 100)\n",
      "(852,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "fcs = np.load('../local/fcs/sparse_fcs_100_unrelated.npy')\n",
    "print(fcs.shape)\n",
    "fcs = fcs[:10]\n",
    "print(fcs.shape)\n",
    "labels = np.load('../local/gender_labels/unrelated_gender_labels.npy')\n",
    "print(labels.shape)\n",
    "labels = labels[:10]\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc48f6-d5a5-43a0-965a-d44f191739b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6b567b-4e9d-44d3-8c17-ee72ac4b9240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_GRAPHS = fcs.shape[0]\n",
    "N_GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec72105c-989f-4f43-be52-da8e04c69332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 0.75)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERCENT = 0.75 \n",
    "N_TRAINING_SAMPLES = int(np.floor(PERCENT*N_GRAPHS))\n",
    "N_TRAINING_SAMPLES, N_TRAINING_SAMPLES/N_GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8dc134-2b92-42fb-be06-1080918d4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../local/graph_datasets/hcp/'\n",
    "dataset = create_graph_dataset(sparse_fcs=fcs, root=root, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e32ac0-86e1-4c76-9d68-a4809c7b146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: HCPDataset(852):\n",
      "====================\n",
      "Number of graphs: 852\n",
      "Number of features: 8\n",
      "Number of classes: 2\n",
      "\n",
      "First Graph: Data(x=[100, 8], edge_index=[2, 1332], edge_attr=[1332], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 100\n",
      "Number of edges: 1332\n",
      "Average node degree: 13.32\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "graph = dataset[0]\n",
    "print()\n",
    "print(f'First Graph: {graph}')\n",
    "print('=============================================================')\n",
    "print(f'Number of nodes: {graph.num_nodes}')\n",
    "print(f'Number of edges: {graph.num_edges}')\n",
    "print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {graph.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {graph.has_self_loops()}')\n",
    "print(f'Is undirected: {graph.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8adc42-6dfa-426c-a090-af0becfcbac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8. ,  8. ,  0. ,  4.4,  4.4,  0. ,  0. ,  0.7],\n",
       "       [11. , 11. ,  0. ,  5.2,  5.2,  0. ,  0. ,  0.7],\n",
       "       [25. , 22. ,  3. ,  9.3, 10.6, -1.3,  0.1,  0.5]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(graph.x[:3,:].numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76355d18-945d-4cef-a5f9-92bb85fb44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:446 M:406 - 0.910\n"
     ]
    }
   ],
   "source": [
    "num_pos = sum(1 for data in dataset if data.y == 1)\n",
    "num_neg = len(dataset) - num_pos\n",
    "print(f'F:{num_pos} M:{num_neg} - {num_neg/num_pos:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b4addc-4e59-40c4-9b39-1f8ed6e8748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 639\n",
      "Number of test graphs: 213\n"
     ]
    }
   ],
   "source": [
    "dataset_shuffled = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset_shuffled[:N_TRAINING_SAMPLES]\n",
    "test_dataset = dataset_shuffled[N_TRAINING_SAMPLES:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a130b6-95ee-407d-a520-376006a98cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)#, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)#, shuffle=False)\n",
    "# for step, data in enumerate(train_loader):\n",
    "#     print(f'Step {step + 1}:')\n",
    "#     print('=======')\n",
    "#     print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "#     print(data)\n",
    "#     print(f'Graphs to aggregate: {len(np.unique(data.batch))}')\n",
    "#     print(np.unique(data.batch))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42abe45c-9a92-4189-9253-c25a8388f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels, num_heads=1, dropout=0.5):\n",
    "        super(AttentionGNN, self).__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(dataset.num_node_features, hidden_channels) # SAGEConv, GATConv, GATv2Conv, GCNConv\n",
    "        #self.conv1 = GATConv(in_dim, hidden_channels, heads=num_heads, concat=True)#, dropout=dropout)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.dropout1 = torch.nn.Dropout(0.7)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Attention-based graph-level aggregation\n",
    "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_channels * num_heads, 1))\n",
    "        nn.init.xavier_uniform_(self.attention_weights)  # Initialize attention weight\n",
    "\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Linear(hidden_channels * num_heads, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "        node_embeddings = self.conv1(x, edge_index)\n",
    "        node_embeddings = self.bn1(node_embeddings)\n",
    "        node_embeddings = self.relu1(node_embeddings)\n",
    "        node_embeddings = self.dropout1(node_embeddings)\n",
    "\n",
    "        # Step 2: Compute attention scores for each node in the graph\n",
    "        attention_scores = torch.matmul(node_embeddings, self.attention_weights)  # (num_nodes, 1)\n",
    "        attention_scores = torch.sigmoid(attention_scores)  # Normalize scores to [0,1]\n",
    "        \n",
    "        # Step 3: Compute graph embedding as weighted sum of node embeddings\n",
    "        weighted_embeddings = node_embeddings * attention_scores  # (num_nodes, hidden_dim * num_heads)\n",
    "        graph_embedding = global_add_pool(weighted_embeddings, batch)  # (num_graphs, hidden_dim * num_heads)\n",
    "\n",
    "        # Step 4: Compute logits for binary classification\n",
    "        logits = self.classifier(graph_embedding)  # (num_graphs, 1)\n",
    "        \n",
    "        return logits, attention_scores  # Return logits and node attention scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c09a49-489e-4748-a382-a548cdab2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         data = data.to(device)\n",
    "         optimizer.zero_grad()\n",
    "         #print(f'Graphs in batch: {data.num_graphs}') \n",
    "         #print(f'data: {data}')\n",
    "         y_logits,_ = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         #print(y_logits.shape)\n",
    "        \n",
    "         #print(f'y_hat:{out.shape}')\n",
    "         #print(out)\n",
    "         y_logits = y_logits.to(device)\n",
    "         loss = criterion(y_logits.float(), torch.unsqueeze(data.y.float().to(device),1))  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # # Prevent exploding gradients by clipping\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         #optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         data = data.to(device)\n",
    "         y_logits,_ = model(data.x, data.edge_index, data.batch)\n",
    "         y_probs = torch.sigmoid(y_logits)\n",
    "         y_pred = (y_probs > 0.5).float()\n",
    "         y_pred = y_pred.to(device)\n",
    "         correct += int((y_pred.squeeze() == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d58e3e7-75f4-465b-8cb5-5ce92c843de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   4,   8,  16,  32,  64, 128, 256, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a83b28-e970-43dc-ab11-5cb6e5778016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: 000, Train Acc: 0.4836, Test Acc: 0.4977\n",
      "Epoch: 500, Train Acc: 0.6103, Test Acc: 0.6291\n",
      "Epoch: 1000, Train Acc: 0.6714, Test Acc: 0.6714\n",
      "Epoch: 1500, Train Acc: 0.6980, Test Acc: 0.6620\n",
      "Epoch: 2000, Train Acc: 0.7152, Test Acc: 0.6432\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10001\n",
    "metrics = np.empty((2,EPOCHS))\n",
    "\n",
    "model = AttentionGNN(hidden_channels=128)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0005,  weight_decay=1e-4, amsgrad=True)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    metrics[0,epoch] = train_acc\n",
    "    metrics[1,epoch] = test_acc\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8649f33-097d-45bb-a769-eb2a6221dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.shape)\n",
    "df = pd.DataFrame({'epoch': range(EPOCHS)[0::100], 'train': metrics[0,:][0::100], 'test': metrics[1,:][0::100]})\n",
    "df_melted = df.melt(id_vars='epoch', var_name='series', value_name='accuracy')\n",
    "sns.lineplot(x='epoch', y='accuracy', hue='series', data=df_melted)\n",
    "plt.plot([0,EPOCHS],[0.5,0.5], c='r', linestyle='--')\n",
    "plt.plot([0,EPOCHS],[0.6,0.6], c='gray', linestyle='--')\n",
    "plt.plot([0,EPOCHS],[0.7,0.7], c='gray', linestyle='--')\n",
    "plt.plot([0,EPOCHS],[0.8,0.8], c='gray', linestyle='--')\n",
    "plt.xlim(0,EPOCHS)\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e69fb9-9b40-40ac-ac92-6a4e3892fa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04650e-7952-4d34-967e-d985370dc081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
